서비스 초기에는 DB 부하가 크지 않기 때문에 기본 설정만으로도 시스템이 잘 동작한다. 하지만 사용자 수가 증가하고 데이터가 누적됨에 따라 **CPU 사용률과 디스크 I/O가 급격히 증가**하면, 단순히 CPU 업그레이드나 메모리 확장만으로는 감당할 수 없는 병목이 발생할 수 있다.  
결과적으로 **서비스 지연 또는 장애 발생**으로 이어질 수 있기 때문에, **물리적 자원 확장보다 효과적인 방법은 소프트웨어적인 튜닝**이다.

성능 최적화 방법은 크게 두 가지로 나뉜다.
1. **SQL 튜닝**: 질의문 최적화 (인덱스 활용, 실행 계획 조정 등)
2. **DB 객체 및 인프라 최적화**: 테이블 구조, 인덱스 구조, 로그 구성, 볼륨 배치 등

## 데이터베이스 최적화
### 1. DB 볼륨 분리 구성
데이터베이스 설치 시 데이터베이스 데이터 볼륨과 데이터베이스 로그를 별도의 디스크에 분리해 저장하는 것이 좀 더 성능을 높일 수 있는 방법이다.

데이터 볼륨, 인덱스 볼륨과 같은 데이터베이스 볼륨에 서 발생하는 I/O는 대부분 랜덤 I/O 형태이고 데이터베이스 로그에서 발생하는 I/O는 순차 I/O 형태이므 로, 물리적인 디스크를 분리해 I/O 형태를 분산해 서로 영향받지 않는 구조가 성능상 유리하다.

### 2. 로그 설정 최적화
다음으로, 로깅 관련 몇 가지 파라미터와 구성에 대해 알아보자. 네이버에서 데이터베이스 로그 파일 크기 표준은 500MB다. 로그는 특성상 삭제와 생성이 반복되기 때문에 크기가 500MB 이상이면 성능에 좋지 않다.

#### 로그 파일 크기
- `log_file_size`: 단일 로그 파일의 크기
- 네이버 기준 표준: **500MB**
- 이유: 로그 파일은 생성/삭제가 반복되는데, **크기가 너무 크면 삭제 시 시스템 I/O 부하**가 커진다.

#### 보관 로그 최대 개수
- `log_max_archives`: 보관 로그 최대 개수
- 너무 작으면 복구용 로그가 부족하고, 너무 크면 **삭제 처리 시 부하**가 커짐

#### 보관 로그 삭제 간격
- `remove_log_archive_interval_in_secs`: 보관 로그 삭제 주기 (초 단위)
- 디폴트는 빠르게 삭제하지만, 대량 삭제 시 I/O 폭증으로 서버 지연 발생 가능
- **권장 값: 60초**
- 효과: 보관 로그를 **천천히 나눠서 삭제**해 마스터 서버의 순간 I/O 부하를 줄임

### 3. 체크포인트 속도 조절
 데이데이터베이스 체크포인트 시에도 마스터 데이터베이스에 영향을 주지 않도록 천천히 디스 크에 반영해야 할 때가 있다. 특히 마이그레이션이나 대량 배치로 인해 데이터 변경이 많이 발생하는 경우 이 설정이 반드시 필요하다
- `checkpoint_sleep_msecs`: 일정량 페이지 반영 후 **쉬는 시간 (ms)**
- 너무 크게 설정하면 오히려 체크포인트 작업이 계속 밀릴 수 있으니 적정한 값으로 설정
- 네이버에서는 10ms 정도로 설정하 는 것이 표준


## 질의 최적화
큐브리드 질의를 튜닝하려면 먼저 큐브리드에서 어떤 과정을 거쳐 질의가 실행되는지 정확하게 아는 것이 중요하다.  이 중 가장 복잡한 과정이라면 단연코 질의 최적화기(query optimizer)라 할 수 있다. 

![[IMG-20250716191947375.png]]
질의 최적화기는 DBMS 핵심 엔진에 속한다. 
질의 최적화기는 질의를 가장 빠르고 효율적으로 실행할 계 획을 수립하고 그중 최적의 실행 계획을 선택한다.

### 각 단계 설명
#### 1. SQL 컴파일
SQL은 문자열 형태로 입력되므로 DBMS가 이해할 수 있는 구조로 변환해야 한다.  
이때 생성되는 트리가 **파스 트리(parse tree)** 이며, 이는 이후 질의 최적화의 기준이 된다.

#### 2. 파스 트리 분석
최적화기는 파스 트리를 기반으로 어떤 테이블과 칼럼이 필요한지 파악한다.

#### 3. 통계 정보 수집
최적의 실행 계획을 세우기 위해 **데이터베이스 통계 정보**를 참조한다.
질의 최적화기(Query Optimizer)가 개입하여, 다양한 실행 계획 중에서 **비용이 가장 낮은 계획**을 선택한다.
- 플랜 캐싱이 된 경우, 이전 실행 계획(XASL)을 재사용하여 이 단계를 생략할 수 있다.

#### 4. 실행 계획 수립 및 선택
다양한 실행 계획 후보를 만들고, 그중에서 **비용이 가장 낮은 실행 계획을 선택**한다.


### 규칙 기반 vs 비용 기반
 DBMS의 질의 최적화기는 작동 방식에 따라 `규칙 기반 최적화기(rule-based optimizer)`와 `비용 기반 최 적화기(cost-based optimizer)`로 구분할 수 있다. 
 
 `규칙 기반 최적화기`는 이용 가능한 인덱스 유무, 질의에 사용되는 연산자 종류, 참조하는 테이블 순서에 따른 우선순위 규칙을 정해두고 이 규칙에 따라 질의 실행 계획을 생성한다.
 
반면 `비용 기반 최적화기`는 통계 정보를 고려해 질의 실행 계획 후보를 생성하고 총 비 용이 가장 낮은 질의 실행 계획을 선택한다. 

> 큐브리드는 **비용 기반 최적화기를 기본**으로 사용하되, **일부 규칙 기반 전략도 혼합**하여 사용한다.

#### 비용 기반 최적화기의 가장 중요한 요소
비용 기반 최적화기의 가장 중요한 요소는 `통계 정보`다
통계 정보가 부정확하면 엉뚱한 실행 계획이 선택되어 **성능이 급격히 저하**될 수 있다.

| 항목                  | 설명                  |
| ------------------- | ------------------- |
| 테이블 레코드 수           | 총 행(row) 수          |
| 힙 페이지 수             | 테이블의 데이터 페이지 수      |
| 칼럼 개수               | 테이블의 컬럼 수           |
| 인덱스 전체 페이지 수        | 인덱스 트리 전체 크기        |
| 리프 페이지 수            | 인덱스의 단말 노드 수        |
| 트리 깊이               | 인덱스 B-Tree의 depth   |
| 고유값 개수              | 특정 컬럼의 distinct 값 수 |
| 데이터 분포              | 값의 분산 정도 (히스토그램 등)  |
| 숫자 자료형 데이터의 최솟값/최댓값 | 예: -999 ~ 123456    |

이 정보는 데이터가 증가함에 따라 자동으로 수집되지 않기 때문에 주기적으로 통계 정보를 갱신해야 하며, cubrid 유틸리티(cubrid optimizedb)나 질의(UPDATE STATISTICS ON)를 사용해 통계 정보를 갱신 할 수 있다. 
큐브리드 9.2까지는 통계 정보를 갱신하려면 테이블 전체를 스캔하면서 상당한 비용이 들기 때 문에 대용량 테이블일수록 테이블 사용이 적을 때 통계 정보를 갱신하는 것이 좋다.
그러나 9.3부터는 통계 정보를 샘플링하므로 통계 정보 갱신에 대한 부담이 적다.


## 질의 비용 확인
질의 성능을 분석할 때는 단순히 실행 시간이 아닌, **물리적/논리적 I/O**의 양도 함께 봐야 한다. CUBRID는 `trace on`, `trace off` 명령어로 질의 수행 중의 **I/O 통계 정보(trace statistics)**를 확인할 수 있다.

수행 결과에는 많은 값이 출력되는데, I/O 비용 통계 정보는 다음 4가지다

| 항목                       | 설명                                      |
| ------------------------ | --------------------------------------- |
| `Num_data_page_fetches`  | 데이터 페이지를 읽어들인 횟수 (메모리에서든 디스크에서든 포함) |
| `Num_data_page_dirties`  | 데이터 페이지를 변경한 횟수 (수정된 페이지 수)         |
| `Num_data_page_ioreads`  | 디스크에서 데이터 페이지를 실제로 읽은 횟수            |
| `Num_data_page_iowrites` | 디스크에 변경된 데이터 페이지를 쓴 횟수              |


