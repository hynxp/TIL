## Primary Key 생성 전략
대규모 시스템에서는 단순한 auto_increment PK만으로는 분산 환경, 보안, 성능 요구사항을 충족하기 어렵다. 이 장에서는 다양한 PK 생성 전략과 그 선택 기준을 다룬다.

### 1. DB auto_increment 방식
DB에서 기본적으로 제공하는 auto_increment 방식을 사용하는 경우, 분산 데이터베이스 환경에서는 PK 중복 문제가 발생할 수 있다. 여러 샤드에서 동일한 PK를 가질 수 있기 때문에 식별자의 유일성이 보장되지 않는다.

또한, auto_increment는 클라이언트에 식별자를 노출했을 때 보안 이슈도 발생할 수 있다. 예를 들어, 방금 가입했는데 `user_id`가 1,000이라면 사용자는 이 시스템에 약 1,000명의 사용자가 있다는 사실을 유추할 수 있다.

그럼에도 불구하고 auto_increment는 간단하기 때문에 다음과 같은 상황에서는 유리할 수 있다.

- 보안 문제를 크게 고려하지 않는 경우
- 단일 DB를 사용하는 경우
- 애플리케이션에서 PK 중복을 직접 관리하거나 구분할 수 있는 경우

보안 문제만 해결하고 싶다면 다음과 같은 구조도 가능하다

- **PK**: id(auto_increment)
- **unique index**: article_id(UUID 등)

이 경우, 클라이언트는 article_id만 사용하고, 실제 DB 내부에서는 id를 통해 식별하는 구조이다. 하지만 이 경우, article_id를 통한 조회는 `Secondary Index`를 통해 접근하게 되므로, 다음과 같은 문제가 있다

- PK 접근 → `key=PRIMARY`
- 유니크 인덱스 접근 → `key=idx_article_id`

별도 식별자를 사용하면 Secondary Index를 통해 포인터를 찾고, Clustered Index를 다시 접근해야 하므로 조회 비용이 증가하게 된다.

### 2. 유니크 문자열 또는 숫자
UUID나 난수 기반의 고유한 값을 생성하여 PK로 지정할 수 있다. 
이 방식은 분산 환경에서 중복 가능성이 없고, 유일한 값을 간단하게 생성할 수 있다는 장점이 있다.

하지만 Clustered Index는 항상 정렬된 상태를 유지해야 하므로, 무작위로 삽입되는 UUID 값은 페이지 분할이나 B+ Tree 재구성을 자주 발생시킨다. 
결과적으로 디스크 I/O가 증가하고, 전체 삽입 성능이 저하된다. PK를 이용한 범위 조회가 필요하다면, 디스크에서 랜덤 I/O가 발생하기 때문에, 순차 I/O보다 성능 저하가 발생한다.


### 3. 유니크 정렬 문자열
ULID, UUID v7 등의 알고리즘은 정렬 가능한 문자열을 기반으로 한다. 이 방식은 삽입 성능 저하 문제를 해결하면서도 분산 환경과 보안 문제를 모두 해결할 수 있다.

128비트 문자열을 사용하므로 저장 공간이 크고, 비교 연산 비용도 증가한다. Clustered Index는 PK를 기준으로 정렬되기 때문에 PK가 커지면 그에 따라 성능 저하가 발생할 수 있다.

### 4. 유니크 정렬 숫자
대표적인 예는 Snowflake, TSID 등의 알고리즘이다. 시간 기반으로 정렬이 가능하며, 고유한 값을 생성할 수 있다. Snowflake는 64비트를 사용하므로 저장 공간이 적고, 정렬된 상태로 빠르게 삽입할 수 있어 성능이 좋다.

이 게시판 시스템에서는 Snowflake 기반의 유니크 정렬 숫자를 PK로 사용했다. 
분산 환경에 대한 PK 중복 문제와 보안 문제를 해결한다


## 인덱스에 대한 이해
대규모 게시판 시스템에서 성능을 좌우하는 요소 중 하나는 인덱스 구조에 대한 이해다. MySQL의 InnoDB 스토리지 엔진은 **B+ Tree** 기반의 인덱스를 사용하며, 다음과 같은 특징이 있다.

- 데이터가 정렬된 상태로 저장된다.
- 검색, 삽입, 삭제 연산을 로그 시간에 수행할 수 있다.
- 트리 구조에서 leaf node들이 연결되어 있어 범위 검색에 효율적이다.

### Clustered Index
InnoDB에서는 테이블마다 자동으로 **Clustered Index**가 생성된다. 일반적으로 **Primary Key**를 기준으로 하며, leaf node에는 실제 **행 데이터(row data)**가 저장된다.

즉, Primary Key를 통해 데이터를 조회할 경우, Clustered Index를 한 번만 탐색하면 된다.

•Clustered Index는 leaf node의 값으로 행 데이터(row data)를 가진다.


![[IMG-20250703024808761.png]]
테이블에 Primary Key를 정렬 기준으로 하는 인덱스가 자동으로 생성된다.

leaf node에는 행 데이터(row data)를 가지고 있다.

![[IMG-20250703024814629.png]]
`article` 테이블에서는 `article_id`를 기준으로 Clustered Index가 생성되어 있으며, 이 인덱스의 leaf node에 각 게시글의 실제 row 데이터가 포함된다. 
따라서 Primary Key를 이용한 조회는 곧 Clustered Index를 활용한 고속 조회가 된다.

### Secondary Index
그렇다면 사용자가 생성한 인덱스는 어떤 구조일까? 바로 **Secondary Index**이다.

Secondary Index는 다음과 같은 구조를 가진다.
- key: 사용자가 지정한 인덱스 컬럼
- leaf node: 해당 컬럼 값 + 해당 row로 접근하기 위한 포인터 (즉, Primary Key)

즉, 실제 row 데이터는 가지고 있지 않으며, Clustered Index를 한 번 더 따라가야 데이터를 조회할 수 있다.

즉, Secondary Index를 통한 조회는 다음 두 단계가 필요하다.
1. Secondary Index에서 PK를 찾는다.
2. Clustered Index를 통해 해당 row data에 접근한다.

이 때문에 Secondary Index는 조회 비용이 상대적으로 높다.


![[IMG-20250703024857133.png]]
Secondary Index는 인덱스에 지정한 컬럼을 key로 가진다.
그리고 leaf node의 데이터는 인덱스 컬럼 데이터,데이터에 접근하기 위한 포인터(Primary Key)를 가진다

우리가 생성한 board_id, article_id 인덱스에 대입해보자.
article_id는 인덱스 컬럼 데이터이면서 데이터에 접근하기 위한 포인터이다.

![[IMG-20250703024912168.png]]
Primary Key를 이용한 데이터 조회는 Clustered Index를 통해 데이터를 빠르게 찾을 수 있었다.
그렇다면, Secondary Index를 이용한 조회는 어떻게 처리되는 것일까?

Secondary Index는 데이터에 접근하기 위한 포인터만 가지고 있다.
그리고 데이터는 Clustered Index가 가지고 있다.
Secondary Index를 통해 데이터가 조회되는 과정을 살펴보자.


즉
•Secondary Index를 이용한 데이터 조회는, 인덱스 트리를 두 번 타고 있는 것이다.

1. Secondary Index에서 데이터에 접근하기 위한 포인터를 찾은 뒤,
2. Clustered Index에서 데이터를 찾는다.


이러한 이중 탐색 구조를 실제 쿼리에 대입해서 살펴보자.
```sql
select * from article
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
이 쿼리는 다음 과정을 거친다.

1. `(board_id, article_id)` 인덱스를 사용하는 Secondary Index에서 조건에 맞는 article_id를 찾는다.
2. 찾은 article_id를 사용해 Clustered Index에서 실제 게시글 row를 찾는다.
3. offset 1,499,970번까지 반복하며 skip하고, 30개를 추출한다.

즉, offset이 클수록 성능이 급격히 저하되는 구조다.

### 인덱스 활용 최적화
그러면 이 구조에서 우리가 만든 `(board_id, article_id)` 인덱스를 최대한 효율적으로 사용하는 방법은 무엇일까?

**핵심 아이디어**는 다음과 같다.

- Secondary Index에서 먼저 필요한 30건의 article_id만 추출한다.
- 그 후, 해당 article_id에 대해서만 Clustered Index를 탐색해 데이터를 가져온다.
- article_id는 Clustered Index에 접근하지 않아도 가져올 수 있는 정보일지 모른다.


우선, 다음과 같이 필요한 컬럼만 추출하는 쿼리를 실행한다.
```sql
select board_id, article_id from article
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
이 쿼리는 완전히 Secondary Index만을 활용하여 article_id 목록을 얻는다. 
이후, 이 결과를 원본 테이블과 join하여 실제 데이터를 가져온다.

이제 추출된 30건의 article_id에 대해서만 Clustered Index에 접근하면 된다!
30건의 article_id를 sub query의 결과로 만들고, article 테이블과 join해보자.
```sql
select * from (
	select article_id from article
	where board_id = 1
	order by article_id desc
	limit 30 offset 1499970
) t left join article on t.article_id = article.article_id;
```
이 방식은 다음과 같은 장점을 가진다.

- 1,499,970건을 모두 skip하며 Clustered Index를 탐색하는 기존 방식보다 훨씬 빠르다.
- Secondary Index는 작은 사이즈의 트리이기 때문에 탐색이 빠르다.
- 최종적으로 필요한 30건에 대해서만 Clustered Index 접근이 이루어진다.

실제 테스트 결과는 다음과 같다.

|방식|처리 시간|
|---|---|
|기존 방식 (전체 skip)|약 4초|
|인덱스 활용 + join 방식|약 0.2초|
50,000번 페이지에서 30개의 게시글을 추출하는 상황에서, 약 20배 성능 개선 효과를 얻을 수 있었다.


## 페이징
대규모 게시판 시스템에서 페이징 처리를 할 때, 정말로 **모든 게시글 수를 세는 것이 필요할까**? 이 질문에서 출발해보자.

### 전체 게시글 수는 반드시 필요하지 않다
대부분의 시스템에서 페이지네이션 UI를 구현할 때, 다음과 같은 화면을 구성하게 된다.

- 한 페이지에 30개의 게시글이 노출된다.
- 사용자는 10페이지 단위로 이동할 수 있다.

이 상황에서 사용자가 어떤 페이지 범위에 있는지에 따라 보여지는 페이지 번호와 버튼은 달라진다.
![[IMG-20250703025434280.png]]
예를 들어,

- 사용자가 **1~10번 페이지**에 있을 경우  
    → 1~10번 페이지 번호 + 다음 버튼만 활성화  
    → 이때 필요한 정보는 **301개 이상의 게시글이 있는가** 여부
    
- 사용자가 **11~20번 페이지**에 있을 경우  
    → 11~20번 페이지 번호 + 이전/다음 버튼 활성화  
    → 이때 필요한 정보는 **601개 이상의 게시글이 있는가** 여부
    
- 사용자가 **21~30번 페이지**에 있을 경우  
    → 21~30번 페이지 번호 + 이전/다음 버튼 활성화  
    → 이때 필요한 정보는 **901개 이상의 게시글이 있는가** 여부

이처럼 실제로는 전체 게시글 수가 아니라, **현재 위치에서 다음 버튼을 보여줄 수 있는지 판단할 수 있을 정도의 개수**만 알면 된다.

> 전체 데이터를 대상으로 count를 수행하는 것은 매우 비용이 큰 작업이다. 하지만 위와 같은 방식으로 일부 게시글 수만 조회하면, 훨씬 효율적인 페이징 처리가 가능하다.

### 일부 게시글 수만 조회해도 충분하다
예를 들어, 현재 페이지가 7페이지일 때는 **최소 301개**의 게시글이 있는지를 확인하면 된다. 301개 이상이면 다음 버튼을 보여주고, 아니면 보여주지 않으면 된다.

### 페이징 번호 계산 공식
이 로직을 일반화하면 다음과 같은 공식으로 계산할 수 있다.
### 페이징 번호 공식
```
필요한 게시글 수 = (((n - 1) / k) + 1) * m * k + 1
```

|기호|의미|
|---|---|
|n|현재 페이지 번호|
|m|페이지당 게시글 수|
|k|한 번에 보여줄 페이지 개수 (예: 10)|

계산 시 `(n - 1) / k`는 **정수 나눗셈**이며, 소수점 이하는 버린다.

#### 예시 1
- 현재 페이지: `n = 7`
- 게시글 수: `m = 30`
- 페이지 묶음: `k = 10`

```
(((7 - 1) / 10) + 1) * 30 * 10 + 1
→ ((6 / 10) + 1) * 300 + 1
→ (0 + 1) * 300 + 1 = 301
```
즉, 301개의 게시글이 있는지 확인하면 된다.

#### 예시 2
- 현재 페이지: `n = 12`
- 게시글 수: `m = 30`
- 페이지 묶음: `k = 10`

```
(((12 - 1) / 10) + 1) * 30 * 10 + 1
→ ((11 / 10) + 1) * 300 + 1
→ (1 + 1) * 300 + 1 = 601
```
즉, 601개의 게시글이 있는지 확인하면 된다.


### 정리
- **전체 게시글 수를 count할 필요는 없다.**
- **현재 페이지 기준으로 다음 버튼이 필요한지만 판단하면 된다.**
- **공식을 활용하면 필요한 게시글 개수를 빠르게 계산할 수 있다.**
- **이는 페이징 UI 렌더링 성능을 개선하는 데 매우 유용하다.**

이 전략은 페이지 수가 많고, offset이 큰 상황에서도 성능을 유지할 수 있도록 도와주는 핵심 기법이다.