## JVM에서 ML 서빙을 해야하는 이유를 얻고 가면 된다!

ML에서 파이썬을 빼놓을 수 없다.
라이브러리가 다 파이썬 기반이다.

하지만
### 프로덕션에서 파이썬이 가지는 어려움
1. 성능 및 병렬처리 제약
	1. 멀티코어로 돌려도 싱글코어의 효과가 남
2. 패키지 및 환경 관리 복잡성
3. 대규모 서비스의 운영 한계
	1. 위의 이유들로, 타입 불확성?

### 그럼 다른 방법은 뭐가 있냐? ML 추론 서버/엔진 이용
like 엔비디아, AWS, LLM, Oci

근데 이것도 제약 사항이 많음
1. 구축 및 운영 복잡성
	1. 장애 대응, 
2. 벤더 종속성 및 기술 지원 한계
3. 리소스 및 비용 부담

-> 역시 JVM인가?

### 그래서 JVM에서 어떻게 ML서빙을 하냐
ONNX(오닉스), 텐서플로우, DJL(Deep Java Library)-> DJL은 나머지에 비해 고수준? 고성능?


## DJL
- AI 전문가가 아니어도 사용 가능하다라고 Overview에 적혀있음
- 다양한 모델(Model Zoo)을 활용할 수 있음 -> Hugging Face

### ML 서빙 활용 예시(커머스)
- 검색
- 추천
- 리뷰 분석
- 검수

#### 리뷰 분석
MLP.Set  ANY 이런거처럼 분석 세팅만 하면 됨


### 한계
저수준 제어가 어렵다.
- CPU를 48코어 할당하기도 하고
- 메모리를 몇 백기가 할당하기도 하고
- 하드 웨어 성능을 쩔게 쥐어짜내야 함

### 해결
이때 오닉스랑 텐서플로우를 사용할 수 있음

#### 텐서플로우
- 동적 배치 처리 가능
- 하드웨어 세밀 조정? 가능한 듯 -> 메모리 팩션 0.9설정 이런거 함, 병렬 스레드 설정도 가능
- Zero-copy 메모리 최적화 가능


-> 1000만개 문서도 1s도 안 걸림


그래서 JVM 서빙이 답인가? 그건 아님, 클라우드 사용하기도 하고 파이썬, 엔진도 쓴다